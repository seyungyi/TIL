# [Apache Spark]

## < 아파치 스파크란? >

- 정의

  - 빅데이터처리를 위한 오픈소스 병렬분산처리 플랫폼
  - 성능과 이용자 편의성을 모두 고려하여 개발이 이루어지고 있음

- 구조

  - 복수의 컴포넌트로 구성됨
  - 병렬분산처리 엔진에 해당하는 스파크 코어를 중심으로 용도에 맞는 여러 라이브러리 제공
  - 종류
    - SQL처리용 라이브러리(스파크 SQL)
    - 스트림처리용 라이브러리(스파크 스트리밍)
    - 머신러닝용 라이브러리(MLlib)
    - 그래프처리용 라이브러리(그래프X)
  - 스파크 코어
    - 데이터소스로 HDFS 뿐만 아니라 하이브, HBase,PostgreSQL, MySQL, CSV파일 등도 받아들일 수 있음

- 활용 사례

  - 대량의 데이터를 고속 병렬분산처리

  - 데이터소스로부터 데이터를 읽어 들인 뒤 스토리지 I/O와 네트워크 I/O를 최소화하도록 처리

  - 동일한 데이터에 대한 변환처리가 연속으로 이루어지는 경우와 머신러닝처럼 결과셋을 여러 번 반복해 처리하는 경우에 적합

  - 지연이 작게 동작하는 특성을 이용해 스트림처리 가능

  - 세 가지 관점에서의 사례

    1. 머신러닝 적용 사례

       - 머신러닝은 스파크의 전형적인 전용 분야
       - 추천 광고의 최적화
       - 개인 맞춤형 페이지를 제공하는 엔진에 적용
       - 2013년 - 야후! 타이완 발표
       - 클라우데 - 금융계의 리스크 분석에 스파크를 적용한 사례

    2. 업무처리 적용 사례

       - 대량의 데이터로부터 특정 컬럼이나 조건에 맞는 레코드만 추출하고 해당 레코드를 반복해 변환처리한 뒤 최종 집계하는 처리

       - 판매 관리와 고객 관리, 요금 계산과 재고 관리 등의 다양한 업무에서 이루어짐
       - 2014년 - NTT데이터가 실제 운용 중인 업무를 시뮬레이션한 처리를 스파크로 적용한 사례

    3. 스트림처리 적용 사례

       - 미국 우얄라 사가 자사의 비디오를 스트리밍할 때 출력되는 로그 해석에 스파크 스트리밍을 활용하고 배치처리도 이용
       - 우얄라 사가 이용하는 스파크는 동작 기반으로 YARN 채용

- 특징
  - 반복처리와 연속으로 이루어지는 변환처리의 고속화
  - 시행착오에 적합한 환경 제공
  - 서로 다른 처리를 통합해 이용할 수 있는 환경

## < 스파크의 처리 모델 >

### 스파크의 기본적인 자료구조 RDD

- RDD 구조와 특징

  - RDD는 대량의 데이터를 요소로 가지는 분산 컬렉션이다
  - 여러 머신으로 구성된 클러스터 환경에서의 분산처리를 전제로 설계되었고, 내부는 파티션이라는 단위로 나뉨
  - 스파크는 이 파티션이 분산처리 단위임
  - RDD를 파티션 단위로 여러 머신에서 처리하므로 한 대의 머신으로 처리할 수 있는 것보다 더 큰 데이터를 다룰 수 있음
  - 처리 종류
    - 변환
    - 액션
  - 성질
    - 불변 속성을 가지는 성질
    - 생성이나 변환이 지연 평가되는 성질

- RDD 다루기

  - 변환(transformation)
    - RDD를 가공하고 그 결과 새로운 RDD를 얻는 처리
    - 변환처리 후의 RDD가 가지는 요소는 변환처리 전의 RDD에 들어있던 요소를 가공하거나 필터링해 생성
    - 정리 : RDD로부터 다른 RDD를 얻는 '데이터 가공'에 해당하는 조작
  - 구분
    1. 변환처리 저의 RDD가 가지는 요소를, 같은 RDD의 다른 요소들과 관계없이 처리할 수 있는 종류
       - filter : 요소를 필터링함
       - map : 각 요소에 동일한 처리를 적용함
       - flatmap : 각 요소에 동일한 처리를 적욯아고 여러 개의 요소를 생성함
       - zip : 파티션 수가 같고, 파티션에 있는 요소의 수도 같은 두 개의 RDD를 조합해 한쪽의 요소 값을 키로, 다른 한쪽의 요소 값을 밸류로 가지는 쌍(key-value pair)을 만듬
    2. 변환 전의 RDD가 가지는 요소를 같은 RDD의 다른 요소와 함께 처리하는 변환
       - 변환 대상은 키와 밸류의 쌍을 요소로 가지는 RDD
       - 같은 키를 가지는 요소를 한데 모아 처리하는데, 같은 키를 가지는 요소가 전부 같은 파티션에 있어야 함 -> 스파크는 파티션 단위로 독립해 분산처리하기 때문이다
       - 셔플
         - 서로 다른 파티션에 있는 같은 키를 가지는 요소의 자리를 바꾸는 것
         - 변환하기 전의 RDD요소를, 변환 후에 키를 기준으로 각 피션에 배분
         - reduceByKey : 같은 키를 가지는 요소를 집약처리(=같은 키를 가지는 요소들이 가지는 값을 합하는 처리)함
         - join : 두 개의 RDD에서 같은 키를 가지는 요소끼리 조인함
       - 파티셔너
         - 셔플할 때 같은 키를 가지는 요소를 같은 파티션에 모으는 역할을 하는 것
         - 변환 후 RDD의 파티션 수와 파티션 이동의 대상이 되는 요소의 키를 기준으로, 요소를 모을 곳(파티션)을 결정
         - 스파크는 키의 해싯값을 변환 이후 RDD의 파티션 수로 나눈 나머지를 디폴트 기준으로 삼아 모을 곳(파티션)을 결정함
  - 액션(action)
    - RDD 내용을 바탕으로 데이터를 가공하지 않고 원하는 결과를 얻는 조작
    - saveAsTextFile : RDD의 내용을 파일로 출력함
    - collect
    - count : RDD의 요소 수를 셈

- 스파크 분산처리 환경

  - 클러스터 관리 시스템 지원
    - YARN
    - Mesos
      - YARN과 마찬가지로 범용 클러스터 관리 시스템
      - 처리에 할당하는 CPU 코어 수의 분배를 동적으로 바꿀 수 있는 등의 세세한 제어 가능
    - Spark Standalone
      - 스파크에 번들되는 전용 클러스터 관리 시스템
      - 별도의 클러스터 관리 시스템 없이 편리하게 이용가능
    - 각 머신은 '마스터 노드' 또는 '워커 노드' 로 동작함
      - 마스터 노드 : 클러스터 내의 계산 리소스를 집중하며 관리 역할 담당
      - 워커 노드 : CPU코어와 메모리 등 계산 리소스를 제공하고 할당된 처리 실행
  - 애플리케이션 배포와 계산 리소스 요구
    - 스파크로 분산처리시 RDD 생성과 일련의 변환으로 구성된 스파크 애플리케이션을 클라이언트가 클러스터에 배포
    - 클라이언트는 애플리케이션을 배포함과 동시에 애플리케이션 실행에 필요한 이그제큐터의 스펙 지정
    - 이그제큐터(executor) : 워커 노드에서 구동해 스파크 애플리케이션을 분산처리하는 프로세스를 말함
  - 클러스터 내 계산 리소스 확보
  - 드라이버 프로그램 구동
  - 태스크 스케쥴링과 실행

- 드라이버 프로그램

  ```scala
  # HDFS 등의 파일시스템에 저장된 거대한 텍스트파일을 가지고 RDD를 생성함
  val textRDD = sc.textFile("/path/to/huge-text")
  
  # RDD의 각 요소에 변환을 적용
  val mappedRDD = textRDD.map(text => someFunction(text))
  val filteredRDD = textRDD.filter(processedText => filterFunction(processedText))
  ...
  
  # RDD에 액션을 적용하고, 원래의 텍스트파일을 가공한 결과를 저장
  processedRDD.saveAsTextFile("/path/to/result")
  ```

- 태스크 스케쥴링

  - RDD의 생성과 로드는 지연 평가되므로, RDD가 데이터를 가진 상태가 되는 것(인스턴스화)은 클러스터를 처리할 때
  - 드라이버 프로그램에서 생성된 RDD에는 태스크 작성과 스케쥴링에 필요한 정보가 포함
    - 예1) RDD의 본래 데이터 정보, 또는 변환하기 전의 RDD
    - 예2) RDD 생성에 필요한 데이터를 어떤 식으로 로드해야 하는가? 또는, RDD에 어떤 변환을 실행해야 하는가?
    - 예3) 변환 후 RDD 요소의 형
    - 예4) 변환 후 RDD 파티션의 수
    - 예5) 파티셔너(셔플을 발생시키는 변환 후의 RDD의 경우)
    - 예6) RDD가 영속화 되었는가?

- RDD 영속화

  - 영속화를 만족하는 조건
    - 셔플이 발생하는 변환을 실행하기 직전의 RDD
    - 사용자에 의해 명시적으로 영속화가 선언된 RDD